# LLM Alignment Notebook

This Jupyter notebook allows you to explore and compare input patterns and outputs generated by base (vanilla) and instruction-tuned (or chat-tuned) LLMs.

## Step 1: Install Ollama

To get started, you need to install **Ollama**, which provides access to quantized LLMs locally. Visit the [Ollama website](https://ollama.com/) and follow the instructions to download and install it.

## Step 2: Set Up Python Virtual Environment

Next, create a Python virtual environment and install the necessary dependencies from the `requirements.txt` file:

```bash
python -m venv env
source env/bin/activate
pip install -r requirements.txt
```

## Step 3: Download Llama-3 Models

We will be using the Llama-3 models, including both the base model and the instruction-tuned (text) version. Please note that each model is approximately 5GB in size.

To download the models, run the following commands:

```bash
ollama pull llama3
ollama pull llama3:text
```

## Step 4: Run the Notebook

After downloading the models, open and follow the instructions provided in the code.ipynb notebook to begin your alignment analysis.
